{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83aab9ac",
   "metadata": {},
   "source": [
    "# Бобкова Ксения дз2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cf83b4",
   "metadata": {},
   "source": [
    "Был сформирован небольшой текст из разных источников.\n",
    "Сложными случаями для автоматической разметки показались части речи, которые не везде выделяются, например, причастие, деепричастие. Кроме того, подклассы местоимений, которые не всегда одназначно можно выделить, союзы, которые при разметке могут быть разделены на несколько частей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1852d954",
   "metadata": {},
   "source": [
    "**На следующий день, в обед, Зеленин сидел в чайной и смотрел в окно на бескрайнюю ширь озера. Было ветрено, мрачно, ходуном ходил тёмно-серый взлохмаченный горизонт.\n",
    "Чайной, темно-серый\n",
    "Некому было заняться?\n",
    "Некому\n",
    "Сейчас Зеленин чувствовал себя словно древний мореплаватель, только что миновавший Геркулесовы столбы.\n",
    "Вот представьте, опять-таки, общественный транспорт — автобус только что остановился, открылась передняя дверь с турникетом, чтобы впустить садящихся, а потом уже (чтобы не было зайцев) откроются остальные двери, чтобы выпустить сходящих.\n",
    "А вот этого — ой, как не хватает современному обществу.\n",
    "Если научить учащегося, в первую очередь, вот такой вот простой психологии — переводить гневные выкрики в спокойные замечания, то учащийся скорее поймёт всю вредность профессии преподавателя и просто перестанет его раздражать, или научится, хотя бы, не реагировать на обидные слова.\n",
    "Мужчины плохо понимают женщин, но и сами женщины часто не понимают самих себя.\n",
    "Женщины, обладая терпеливостью и усидчивостью, способны выполнять тонкую и монотонную работу с заданной программой действий \n",
    "«Мой брат в Москве, мы Россию любим, на русских бизнеса нет», — убеждал меня такой «впариватель» возле мечети Байязет в Стамбуле\n",
    "Мы духовны, когда беседуем о чём-то дорогом с товарищем, доверяя его уму и сердцу.\n",
    "А увенчанный славой военачальник был желанным гостем в доме своей племянницы. \n",
    "Несмотря на непогоду, делает сквозь льды проходы.\n",
    "Количество людей, уровень которых позволяет делать последовательной перевод с языка и на язык еще меньше, считается, что таких готовят в языковых ВУЗах.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d6dbe6",
   "metadata": {},
   "source": [
    "В первую очередь, было необходимо записать исходный текст в csv таблицу. Отмечу, что текст в файле уже был разбит по предложениям (строчка - 1 предложение), поэтому требовалось только токенизировать его, а также присвоить id каждому слову для конкретного предложения. Другими словами, все слова конкретного предложения должны иметь один id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cc5762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "from itertools import chain, repeat\n",
    "\n",
    "all_sentences = []\n",
    "with open(\"sentences.txt\",\"rt\", encoding=\"UTF-8\") as f1:\n",
    "    for line in f1:\n",
    "        all_sentences.append(line.rstrip())\n",
    "\n",
    "all_tokens_sent = []\n",
    "for sentence in all_sentences:\n",
    "    tokens = [w.lower() for w in word_tokenize(sentence) if w.isalpha()]\n",
    "    all_tokens_sent.append(tokens)\n",
    "\n",
    "#all tokens\n",
    "all_tokens = list(chain.from_iterable(all_tokens_sent))\n",
    "\n",
    "\n",
    "#get id of sentences\n",
    "id_sentences = []\n",
    "for i in range(len(all_tokens_sent)):\n",
    "    dl = len(all_tokens_sent[i])\n",
    "    id_sentences.extend(repeat(i, dl))\n",
    "\n",
    "#create a dict\n",
    "dict_to_table = {}\n",
    "dict_to_table[\"Word\"] = all_tokens\n",
    "dict_to_table[\"id_sent\"] = id_sentences\n",
    "#\n",
    "#create a table\n",
    "df = pd.DataFrame(dict_to_table)\n",
    "df.to_csv('table.csv', mode='a', index= False , header= True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b09853",
   "metadata": {},
   "source": [
    "Затем вручную таблица была размечена. После же были использованы 3 POS теггера для русского языка, результаты записаны в таблицу по колонкам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce0315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import pandas as pd\n",
    "import stanza\n",
    "#stanza.download('ru')\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('table.csv')\n",
    "\n",
    "#pymorhy - Pos-tag1\n",
    "morph = MorphAnalyzer()\n",
    "tags_pymorhy = []\n",
    "for token in df[\"Word\"]:\n",
    "     t = morph.parse(token)\n",
    "     tag = t[0].tag.POS\n",
    "     tags_pymorhy.append(tag)\n",
    "        \n",
    " #add to csv file\n",
    "df['Pos-tag1'] = tags_pymorhy\n",
    "df.to_csv('table.csv', index=False)\n",
    "\n",
    "#mystem - Pos-tag2\n",
    "mystem = Mystem()\n",
    "tags_mystem = []\n",
    "for token in df[\"Word\"]:\n",
    "     m = mystem.analyze(token)\n",
    "     gr = m[0][\"analysis\"][0][\"gr\"]\n",
    "     pos = gr.split(\"=\")[0].split(\",\")[0]\n",
    "     tags_mystem.append(pos)\n",
    "\n",
    "# #add to csv file\n",
    "df['Pos-tag2'] = tags_mystem\n",
    "df.to_csv('table.csv', index=False)\n",
    "\n",
    "\n",
    "#stanza - Pos-tag3\n",
    "ppln = stanza.Pipeline('ru', processors='tokenize,pos')\n",
    "tags_stanza = []\n",
    "for token in df[\"Word\"]:\n",
    "     doc = ppln(token)\n",
    "     d = doc.to_dict()\n",
    "     s = d[0][0][\"upos\"]\n",
    "     tags_stanza.append(s)\n",
    "\n",
    "#add to csv file\n",
    " df['Pos-tag3'] = tags_stanza\n",
    " df.to_csv('table.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
